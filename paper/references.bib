@article{davis2021low,
  title={From low probability to high confidence in stochastic convex optimization},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Xiao, Lin and Zhang, Junyu},
  journal={Journal of machine learning research},
  volume={22},
  number={49},
  pages={1--38},
  year={2021}
}

@article{nesterov2015universal,
  title={Universal gradient methods for convex optimization problems},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={152},
  number={1},
  pages={381--404},
  year={2015},
  publisher={Springer}
}

@incollection{gasnikov2023randomized,
  title={Randomized gradient-free methods in convex optimization},
  author={Gasnikov, Alexander and Dvinskikh, Darina and Dvurechensky, Pavel and Gorbunov, Eduard and Beznosikov, Aleksandr and Lobanov, Alexander},
  booktitle={Encyclopedia of Optimization},
  pages={1--15},
  year={2023},
  publisher={Springer}
}

@article{nemirovskij1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
  year={1983},
  publisher={Wiley-Interscience}
}

@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}

@article{ghadimi2012optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={4},
  pages={1469--1492},
  year={2012},
  publisher={SIAM}
}

@article{ghadimi2013optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2061--2089},
  year={2013},
  publisher={SIAM}
}

@article{hazan2014beyond,
  title={Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization},
  author={Hazan, Elad and Kale, Satyen},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={2489--2512},
  year={2014},
  publisher={JMLR. org}
}

@article{bousquet2002stability,
  title={Stability and generalization},
  author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
  journal={Journal of machine learning research},
  volume={2},
  number={Mar},
  pages={499--526},
  year={2002}
}

@article{nesterov2008confidence,
  title={Confidence level solutions for stochastic programming},
  author={Nesterov, Yu and Vial, J-Ph},
  journal={Automatica},
  volume={44},
  number={6},
  pages={1559--1568},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{shalev2009stochastic,
  title={Stochastic Convex Optimization.},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
  booktitle={COLT},
  volume={2},
  number={4},
  pages={5},
  year={2009}
}

@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}

@article{juditsky2014deterministic,
  title={Deterministic and stochastic primal-dual subgradient algorithms for uniformly convex minimization},
  author={Juditsky, Anatoli and Nesterov, Yuri},
  journal={Stochastic Systems},
  volume={4},
  number={1},
  pages={44--80},
  year={2014},
  publisher={INFORMS}
}

@inproceedings{harvey2019tight,
  title={Tight analyses for non-smooth stochastic gradient descent},
  author={Harvey, Nicholas JA and Liaw, Christopher and Plan, Yaniv and Randhawa, Sikander},
  booktitle={Conference on Learning Theory},
  pages={1579--1613},
  year={2019},
  organization={PMLR}
}

@article{harvey2019simple,
  title={Simple and optimal high-probability bounds for strongly-convex stochastic gradient descent},
  author={Harvey, Nicholas JA and Liaw, Christopher and Randhawa, Sikander},
  journal={arXiv preprint arXiv:1909.00843},
  year={2019}
}

@article{gorbunov2020stochastic,
  title={Stochastic optimization with heavy-tailed noise via accelerated gradient clipping},
  author={Gorbunov, Eduard and Danilova, Marina and Gasnikov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15042--15053},
  year={2020}
}

@article{gorbunov2024high,
  title={High-Probability Complexity Bounds for Non-smooth Stochastic Convex Optimization with Heavy-Tailed Noise},
  author={Gorbunov, Eduard and Danilova, Marina and Shibaev, Innokentiy and Dvurechensky, Pavel and Gasnikov, Alexander},
  journal={Journal of Optimization Theory and Applications},
  pages={1--60},
  year={2024},
  publisher={Springer}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{wang2017primal,
  title={Primal-Dual $\pi$ Learning: Sample Complexity and Sublinear Run Time for Ergodic Markov Decision Problems},
  author={Wang, Mengdi},
  journal={arXiv preprint arXiv:1710.06100},
  year={2017}
}

@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}

@article{shalev2013stochastic,
  title={Stochastic dual coordinate ascent methods for regularized loss},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={567--599},
  year={2013},
  publisher={JMLR. org}
}

@article{zhang2017stochastic,
  title={Stochastic primal-dual coordinate method for regularized empirical risk minimization},
  author={Zhang, Yuchen and Xiao, Lin},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={84},
  pages={1--42},
  year={2017}
}

@article{yan2019stochastic,
  title={Stochastic Primal-Dual Algorithms with Faster Convergence than $ O (1/$\backslash$sqrt $\{$T$\}$) $ for Problems without Bilinear Structure},
  author={Yan, Yan and Xu, Yi and Lin, Qihang and Zhang, Lijun and Yang, Tianbao},
  journal={arXiv preprint arXiv:1904.10112},
  year={2019}
}

@inproceedings{zhang2021generalization,
  title={Generalization bounds for stochastic saddle point problems},
  author={Zhang, Junyu and Hong, Mingyi and Wang, Mengdi and Zhang, Shuzhong},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={568--576},
  year={2021},
  organization={PMLR}
}

@article{li2024general,
  title={General procedure to provide high-probability guarantees for stochastic saddle point problems},
  author={Li, Dongyang and Li, Haobin and Zhang, Junyu},
  journal={Journal of Scientific Computing},
  volume={100},
  number={1},
  pages={13},
  year={2024},
  publisher={Springer}
}

@article{воронцова2021выпуклая,
  title={Выпуклая оптимизация},
  author={Воронцова, ЕА and Хильдебранд, РФ and Гасников, АВ and Стонякин, ФС},
  journal={М.: МФТИ},
  year={2021}
}

@article{hsu2016loss,
  title={Loss minimization and parameter estimation with heavy tails},
  author={Hsu, Daniel and Sabato, Sivan},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={18},
  pages={1--40},
  year={2016}
}

@article{гасников2018современные,
  title={Современные численные методы оптимизации. Метод универсального градиентного спуска},
  author={Гасников, Александр Владимирович},
  year={2018},
  publisher={Федеральное государственное автономное образовательное учреждение высшего~…}
}
